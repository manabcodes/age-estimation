{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862b719f-9a5c-45b8-b1d5-af21ff2c0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside your test_classification_model function, add this code where you create the scatter plot\n",
    "# (or create a new function to generate this specific visualization)\n",
    "\n",
    "def create_complete_age_prediction_scatter(predictions, targets, results_dir):\n",
    "    \"\"\"\n",
    "    Create a scatter plot showing ALL data points of predicted vs true ages\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    \n",
    "    # Create the scatter plot with smaller, more transparent points to avoid overplotting\n",
    "    plt.scatter(targets, predictions, alpha=0.3, s=15, color='#3498db', edgecolor='none')\n",
    "    \n",
    "    # Add the reference lines\n",
    "    max_val = max(np.max(targets), np.max(predictions))\n",
    "    min_val = min(np.min(targets), np.min(predictions))\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect prediction')\n",
    "    \n",
    "    # Linear regression line\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    X = targets.reshape(-1, 1)\n",
    "    y = predictions\n",
    "    model.fit(X, y)\n",
    "    slope = model.coef_[0]\n",
    "    plt.plot([min_val, max_val], \n",
    "             [model.predict([[min_val]])[0], model.predict([[max_val]])[0]], \n",
    "             'g-', linewidth=2, \n",
    "             label=f'Actual fit (slope={slope:.2f})')\n",
    "    \n",
    "    # Error margin lines\n",
    "    plt.plot([min_val, max_val], [min_val + 5, max_val + 5], 'k:', linewidth=1.5, label='+5 years')\n",
    "    plt.plot([min_val, max_val], [min_val - 5, max_val - 5], 'k:', linewidth=1.5, label='-5 years')\n",
    "    \n",
    "    # Add detailed count information for each band\n",
    "    unique_preds = np.unique(predictions)\n",
    "    txt = \"Prediction bands:\\n\"\n",
    "    for pred in unique_preds[:10]:  # Show top 10 bands\n",
    "        count = np.sum(predictions == pred)\n",
    "        txt += f\"{pred:.1f}: {count} samples\\n\"\n",
    "    if len(unique_preds) > 10:\n",
    "        txt += f\"... and {len(unique_preds)-10} more bands\"\n",
    "    plt.annotate(txt, xy=(0.98, 0.10), xycoords='axes fraction', \n",
    "                va='top', ha='left', fontsize=6, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add count information to the plot\n",
    "    plt.text(0.98, 0.15, f\"Total samples: {len(predictions)}\", fontsize=6, transform=plt.gca().transAxes,\n",
    "            bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Style the plot\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlabel('True Age')\n",
    "    plt.ylabel('Predicted Age')\n",
    "    plt.title('Age Prediction Results (All Data Points)')\n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    # Make sure we show the full data range\n",
    "    buffer = 5\n",
    "    plt.xlim(min_val - buffer, max_val + buffer)\n",
    "    plt.ylim(min_val - buffer, max_val + buffer)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'complete_age_prediction_scatter.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0948a3-e627-4e0c-b4b2-976f7bf7908b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Test dataset size: 978 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meem/backup/Age Datasets/volo/utils/utils.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
      "/tmp/ipykernel_1456969/4253901567.py:117: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model from: output/volo_d1_gradual_final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 62/62 [00:07<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "Avg Loss: 2.8321\n",
      "Accuracy: 21.78%\n",
      "Avg MAE: 5.17 years\n",
      "Predictions within 1 year: 35.89%\n",
      "Predictions within 3 years: 54.50%\n",
      "Predictions within 5 years: 65.85%\n",
      "Predictions within 10 years: 84.97%\n",
      "\n",
      "Metrics by Age Group:\n",
      "Children (0-12): Accuracy: 42.20%, MAE: 1.59 years, Within 5 years: 95.72% (n=327)\n",
      "Teenagers (13-19): Accuracy: 20.22%, MAE: 5.01 years, Within 5 years: 57.30% (n=89)\n",
      "Young Adults (20-35): Accuracy: 9.13%, MAE: 4.90 years, Within 5 years: 65.22% (n=230)\n",
      "Middle-aged (36-50): Accuracy: 5.93%, MAE: 9.41 years, Within 5 years: 28.81% (n=118)\n",
      "Seniors (51-70): Accuracy: 8.96%, MAE: 9.43 years, Within 5 years: 41.79% (n=134)\n",
      "Elderly (71+): Accuracy: 21.25%, MAE: 7.36 years, Within 5 years: 50.00% (n=80)\n",
      "\n",
      "Worst Predictions:\n",
      "File: 3_0_0_20170110212752045.jpg.chip.jpg, True Age: 3, Predicted: 60, Error: 57.0 years\n",
      "File: 67_1_2_20161219194437956.jpg.chip.jpg, True Age: 67, Predicted: 16, Error: 51.0 years\n",
      "File: 56_1_2_20170109010140329.jpg.chip.jpg, True Age: 56, Predicted: 8, Error: 48.0 years\n",
      "File: 16_0_0_20170104012330536.jpg.chip.jpg, True Age: 16, Predicted: 56, Error: 40.0 years\n",
      "File: 50_1_0_20170110123120845.jpg.chip.jpg, True Age: 50, Predicted: 16, Error: 34.0 years\n",
      "File: 85_1_4_20170110184012572.jpg.chip.jpg, True Age: 85, Predicted: 53, Error: 32.0 years\n",
      "File: 56_1_3_20170109133800445.jpg.chip.jpg, True Age: 56, Predicted: 26, Error: 30.0 years\n",
      "File: 58_1_3_20170104220324390.jpg.chip.jpg, True Age: 58, Predicted: 29, Error: 29.0 years\n",
      "File: 66_0_0_20170109013237361.jpg.chip.jpg, True Age: 66, Predicted: 39, Error: 27.0 years\n",
      "File: 8_0_2_20170103175549207.jpg.chip.jpg, True Age: 8, Predicted: 35, Error: 27.0 years\n",
      "Saved detailed results to age_classification_results-2025-06-17_15-24-05/classification_results.csv\n",
      "Saved summary statistics to age_classification_results-2025-06-17_15-24-05/summary_stats.txt\n",
      "\n",
      "KEY RESULTS SUMMARY:\n",
      "Mean Absolute Error: 5.17 years\n",
      "Percentage within 5 years: 65.85%\n",
      "All results saved in directory: age_classification_results-2025-06-17_15-24-05\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Generate timestamp for file naming\n",
    "timestamp = datetime.now().strftime(\"-%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Dataset class for classification\n",
    "class AgeClassificationDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to CSV with annotations (image_name, age)\n",
    "            img_dir (string): Path to the images\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "        \"\"\"\n",
    "        self.age_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.age_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.age_frame.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        age = self.age_frame.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # For classification, return age as an integer (class label)\n",
    "        age = int(age)  # Ensure age is an integer for classification\n",
    "        \n",
    "        return image, age, self.age_frame.iloc[idx, 0]  # Return filename as well for visualization\n",
    "\n",
    "# Setup VOLO model with classification head\n",
    "def setup_volo_model(checkpoint_path, num_classes=122):\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    # First make sure the VOLO directory is in the Python path\n",
    "    volo_dir = os.path.join(os.getcwd(), 'volo')\n",
    "    if os.path.exists(volo_dir) and volo_dir not in sys.path:\n",
    "        sys.path.append(volo_dir)\n",
    "    \n",
    "    # Now try to import from the volo directory\n",
    "    try:\n",
    "        from volo.models import volo_d1\n",
    "        from volo.utils import load_pretrained_weights\n",
    "    except ImportError:\n",
    "        # If that fails, try direct import (assuming we're in the volo directory)\n",
    "        try:\n",
    "            from models import volo_d1\n",
    "            from utils import load_pretrained_weights\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import VOLO modules. Please make sure you're either:\\n\"\n",
    "                \"1. Running from the VOLO directory, or\\n\"\n",
    "                \"2. Have the VOLO directory in your current working directory\\n\"\n",
    "                \"Current directory: \" + os.getcwd()\n",
    "            )\n",
    "    \n",
    "    # Load the base model with ImageNet weights\n",
    "    model = volo_d1(img_size=224)\n",
    "    \n",
    "    # Load pretrained weights\n",
    "    load_pretrained_weights(\n",
    "        model=model,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        use_ema=False,\n",
    "        strict=False,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    # Replace the classification head for age classification\n",
    "    in_features = model.head.in_features\n",
    "    model.head = nn.Linear(in_features, num_classes)\n",
    "    if hasattr(model, 'aux_head'):\n",
    "        model.aux_head = nn.Linear(model.aux_head.in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load model from trained checkpoint\n",
    "def load_model(model_path, device='cpu', num_classes=122):\n",
    "    \"\"\"\n",
    "    Load the trained model weights\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the trained model checkpoint\n",
    "        device: Device to load the model on ('cuda' or 'cpu')\n",
    "        num_classes: Number of age classes\n",
    "        \n",
    "    Returns:\n",
    "        Loaded model ready for inference\n",
    "    \"\"\"\n",
    "    # Create base model\n",
    "    base_model = setup_volo_model(\n",
    "        checkpoint_path='/home/meem/backup/d1_224_84.2.pth.tar',\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    \n",
    "    # Load the trained weights\n",
    "    print(f\"Loading trained model from: {model_path}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Handle different checkpoint formats\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        base_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        # If the checkpoint is just the state dict\n",
    "        base_model.load_state_dict(checkpoint)\n",
    "    \n",
    "    base_model = base_model.to(device)\n",
    "    base_model.eval()\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "# Run inference and evaluation for classification with detailed metrics\n",
    "def test_classification_model(model_path, model, test_loader, device='cpu', visualize=True, num_samples=10, max_age=100):\n",
    "    \"\"\"\n",
    "    Test the classification model on a dataset and compute detailed metrics\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Device to test on ('cuda' or 'cpu')\n",
    "        visualize: Whether to visualize predictions\n",
    "        num_samples: Number of random samples to visualize\n",
    "        max_age: Maximum age to consider for visualizations\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    all_filenames = []\n",
    "    all_errors = []  # MAE for each sample\n",
    "    all_probabilities = []  # Store softmax outputs\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, ages, filenames in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs = inputs.to(device)\n",
    "            target_ages = ages.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Handle different return formats of VOLO\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]  # Main classification output\n",
    "            \n",
    "            # Calculate probabilities\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, target_ages)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted_classes = torch.max(outputs, 1)\n",
    "            correct += (predicted_classes == target_ages).sum().item()\n",
    "            \n",
    "            # Calculate MAE (treating predictions as continuous values)\n",
    "            mae = torch.abs(predicted_classes.float() - target_ages.float())\n",
    "            \n",
    "            # Save data for detailed analysis\n",
    "            all_preds.extend(predicted_classes.cpu().numpy())\n",
    "            all_targets.extend(target_ages.cpu().numpy())\n",
    "            all_filenames.extend(filenames)\n",
    "            all_errors.extend(mae.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays for easier processing\n",
    "    predictions = np.array(all_preds)\n",
    "    targets = np.array(all_targets)\n",
    "    errors = np.array(all_errors)\n",
    "    probabilities = np.array(all_probabilities)\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    avg_loss = running_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    avg_mae = np.mean(errors)\n",
    "    \n",
    "    # Calculate accuracy within different thresholds\n",
    "    within_1_year = np.mean(errors <= 1) * 100\n",
    "    within_3_years = np.mean(errors <= 3) * 100\n",
    "    within_5_years = np.mean(errors <= 5) * 100\n",
    "    within_10_years = np.mean(errors <= 10) * 100\n",
    "    \n",
    "    # Print overall metrics\n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"Avg Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    print(f\"Avg MAE: {avg_mae:.2f} years\")\n",
    "    print(f\"Predictions within 1 year: {within_1_year:.2f}%\")\n",
    "    print(f\"Predictions within 3 years: {within_3_years:.2f}%\")\n",
    "    print(f\"Predictions within 5 years: {within_5_years:.2f}%\")\n",
    "    print(f\"Predictions within 10 years: {within_10_years:.2f}%\")\n",
    "    \n",
    "    # Calculate metrics by age group\n",
    "    age_groups = [\n",
    "        (0, 12, \"Children (0-12)\"),\n",
    "        (13, 19, \"Teenagers (13-19)\"),\n",
    "        (20, 35, \"Young Adults (20-35)\"),\n",
    "        (36, 50, \"Middle-aged (36-50)\"),\n",
    "        (51, 70, \"Seniors (51-70)\"),\n",
    "        (71, 100, \"Elderly (71+)\")\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nMetrics by Age Group:\")\n",
    "    for start, end, name in age_groups:\n",
    "        mask = (targets >= start) & (targets <= end)\n",
    "        if np.sum(mask) > 0:\n",
    "            group_accuracy = np.mean(targets[mask] == predictions[mask])\n",
    "            group_mae = np.mean(errors[mask])\n",
    "            group_within_5 = np.mean(errors[mask] <= 5) * 100\n",
    "            count = np.sum(mask)\n",
    "            print(f\"{name}: Accuracy: {group_accuracy:.2%}, MAE: {group_mae:.2f} years, Within 5 years: {group_within_5:.2f}% (n={count})\")\n",
    "    \n",
    "    # Find worst predictions\n",
    "    worst_indices = np.argsort(errors)[-10:][::-1]  # Top 10 worst predictions\n",
    "    \n",
    "    print(\"\\nWorst Predictions:\")\n",
    "    for idx in worst_indices:\n",
    "        print(f\"File: {all_filenames[idx]}, True Age: {targets[idx]}, Predicted: {predictions[idx]}, Error: {errors[idx]} years\")\n",
    "    \n",
    "    # Visualize predictions if requested\n",
    "    if visualize:\n",
    "        # Create a directory for results\n",
    "        results_dir = f\"age_classification_results{timestamp}\"\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        # Set common figure parameters for better viewing\n",
    "        plt.rcParams.update({\n",
    "            'font.size': 10,  # Smaller font size\n",
    "            'figure.dpi': 100,  # Lower DPI for smaller file sizes\n",
    "            'savefig.dpi': 150  # Higher DPI for saving but not too high\n",
    "        })\n",
    "        \n",
    "        # 1. Plot a full confusion matrix (no bins) - REDUCED SIZE\n",
    "        # Limit to ages up to max_age for better visualization\n",
    "        cm_limit = min(max_age + 1, max(np.max(targets), np.max(predictions)) + 1)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))  # Reduced from (20, 16)\n",
    "        cm = confusion_matrix(\n",
    "            targets[targets < cm_limit], \n",
    "            predictions[targets < cm_limit], \n",
    "            labels=range(cm_limit)\n",
    "        )\n",
    "        \n",
    "        # For better visibility, apply log scale to the confusion matrix\n",
    "        # Use log(x+1) to handle zeros\n",
    "        cm_log = np.log1p(cm)\n",
    "        \n",
    "        # Create a heatmap\n",
    "        ax = sns.heatmap(cm_log, cmap='viridis', annot=False, \n",
    "                         xticklabels=10, yticklabels=10)\n",
    "        \n",
    "        # Set labels for every 10th tick\n",
    "        tick_positions = np.arange(0, cm_limit, 10)\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_positions)\n",
    "        ax.set_yticklabels(tick_positions)\n",
    "        \n",
    "        plt.xlabel('Predicted Age')\n",
    "        plt.ylabel('True Age')\n",
    "        plt.title('Age Confusion Matrix (Log Scale)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'confusion_matrix_full_log.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Create a heatmap of prediction error by age - REDUCED SIZE\n",
    "        # First, calculate average error for each true age\n",
    "        max_target_age = min(max_age, int(np.max(targets)))\n",
    "        avg_error_by_age = np.zeros(max_target_age + 1)\n",
    "        count_by_age = np.zeros(max_target_age + 1)\n",
    "        \n",
    "        for true_age, error in zip(targets, errors):\n",
    "            if true_age <= max_target_age:\n",
    "                avg_error_by_age[int(true_age)] += error\n",
    "                count_by_age[int(true_age)] += 1\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        mask = count_by_age > 0\n",
    "        avg_error_by_age[mask] = avg_error_by_age[mask] / count_by_age[mask]\n",
    "        \n",
    "        plt.figure(figsize=(8, 4))  # Reduced from (15, 6)\n",
    "        plt.bar(range(max_target_age + 1), avg_error_by_age, alpha=0.7)\n",
    "        plt.xlabel('True Age')\n",
    "        plt.ylabel('Average Error (years)')\n",
    "        plt.title('Average Prediction Error by Age')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'avg_error_by_age.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. NEW: Add cumulative error distribution chart\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        error_thresholds = np.arange(0, 21)  # 0 to 20 years\n",
    "        cumulative_pct = [np.mean(errors <= threshold) * 100 for threshold in error_thresholds]\n",
    "        \n",
    "        plt.plot(error_thresholds, cumulative_pct, marker='o', markersize=4)\n",
    "        plt.axhline(y=90, color='r', linestyle='--', alpha=0.7, label='90% threshold')\n",
    "        plt.axvline(x=5, color='g', linestyle='--', alpha=0.7, label='5-year threshold')\n",
    "        \n",
    "        # Mark the percentage of predictions within 5 years\n",
    "        five_year_pct = np.mean(errors <= 5) * 100\n",
    "        plt.plot(5, five_year_pct, 'ro', markersize=8)\n",
    "        plt.annotate(f\"{five_year_pct:.1f}%\", \n",
    "                     xy=(5, five_year_pct), \n",
    "                     xytext=(7, five_year_pct - 5),\n",
    "                     arrowprops=dict(arrowstyle=\"->\", color='r'))\n",
    "        \n",
    "        plt.xlabel('Error Threshold (years)')\n",
    "        plt.ylabel('Percentage of Predictions (%)')\n",
    "        plt.title('Cumulative Error Distribution')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'cumulative_error_distribution.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 4. NEW: Add pie chart for error thresholds\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        error_categories = [\n",
    "            ('≤1 year', np.sum(errors <= 1)),\n",
    "            ('1-3 years', np.sum((errors > 1) & (errors <= 3))),\n",
    "            ('3-5 years', np.sum((errors > 3) & (errors <= 5))),\n",
    "            ('5-10 years', np.sum((errors > 5) & (errors <= 10))),\n",
    "            ('>10 years', np.sum(errors > 10))\n",
    "        ]\n",
    "        \n",
    "        labels = [f\"{cat[0]}: {cat[1]/len(errors)*100:.1f}%\" for cat in error_categories]\n",
    "        sizes = [cat[1] for cat in error_categories]\n",
    "        colors = ['#2ecc71', '#27ae60', '#f1c40f', '#e67e22', '#e74c3c']\n",
    "        explode = (0.1, 0.05, 0, 0, 0)  # explode the smallest slice\n",
    "        \n",
    "        plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "                shadow=False, startangle=90, textprops={'fontsize': 9})\n",
    "        plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "        plt.title('Distribution of Prediction Errors')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'error_distribution_pie.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 5. NEW: Add bar chart showing percentage of predictions within 5 years by age group\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        \n",
    "        # Calculate percentage within 5 years for each age group\n",
    "        age_group_labels = []\n",
    "        within_5_years_pct = []\n",
    "        \n",
    "        for start, end, name in age_groups:\n",
    "            mask = (targets >= start) & (targets <= end)\n",
    "            if np.sum(mask) > 0:\n",
    "                pct = np.mean(errors[mask] <= 5) * 100\n",
    "                within_5_years_pct.append(pct)\n",
    "                age_group_labels.append(name)\n",
    "        \n",
    "        # Add overall percentage\n",
    "        age_group_labels.append(\"Overall\")\n",
    "        within_5_years_pct.append(within_5_years)\n",
    "        \n",
    "        # Create bar chart\n",
    "        bars = plt.bar(range(len(age_group_labels)), within_5_years_pct, color='#3498db')\n",
    "        \n",
    "        # Add data labels on top of bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{within_5_years_pct[i]:.1f}%',\n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        plt.axhline(y=within_5_years, color='r', linestyle='--', alpha=0.7, label='Overall Average')\n",
    "        plt.xticks(range(len(age_group_labels)), age_group_labels, rotation=45, ha='right')\n",
    "        plt.ylabel('Percentage within 5 years (%)')\n",
    "        plt.title('Predictions Within 5 Years by Age Group')\n",
    "        plt.grid(True, axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'within_5_years_by_age_group.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 6. NEW: Add line chart showing accuracy by exact error threshold\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        \n",
    "        thresholds = list(range(1, 21))  # 1 to 20 years\n",
    "        accuracies = [np.mean(errors <= threshold) * 100 for threshold in thresholds]\n",
    "        \n",
    "        plt.plot(thresholds, accuracies, marker='o', markersize=4, linewidth=2)\n",
    "        \n",
    "        # Highlight specific thresholds\n",
    "        key_thresholds = [1, 3, 5, 10]\n",
    "        for threshold in key_thresholds:\n",
    "            idx = thresholds.index(threshold)\n",
    "            plt.plot(threshold, accuracies[idx], 'ro', markersize=6)\n",
    "            plt.annotate(f\"{accuracies[idx]:.1f}%\", \n",
    "                         xy=(threshold, accuracies[idx]), \n",
    "                         xytext=(threshold+0.5, accuracies[idx]+1),\n",
    "                         arrowprops=dict(arrowstyle=\"->\", color='r'))\n",
    "        \n",
    "        plt.xlabel('Error Threshold (years)')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Accuracy at Different Error Thresholds')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'accuracy_by_threshold.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 7. Create a distance heatmap - REDUCED SIZE\n",
    "        # Calculate prediction distances\n",
    "        distances = predictions - targets\n",
    "        max_distance = min(40, max(abs(np.min(distances)), np.max(distances)))\n",
    "        \n",
    "        # Create a 2D histogram of true ages vs prediction distance\n",
    "        hist_data = np.zeros((max_target_age + 1, 2 * max_distance + 1))\n",
    "        \n",
    "        for true_age, distance in zip(targets, distances):\n",
    "            if true_age <= max_target_age and abs(distance) <= max_distance:\n",
    "                hist_data[int(true_age), int(distance) + max_distance] += 1\n",
    "        \n",
    "        # Normalize by the number of samples at each age\n",
    "        for age in range(max_target_age + 1):\n",
    "            if np.sum(hist_data[age, :]) > 0:\n",
    "                hist_data[age, :] = hist_data[age, :] / np.sum(hist_data[age, :])\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))  # Reduced from (20, 16)\n",
    "        sns.heatmap(hist_data, cmap='viridis', \n",
    "                   xticklabels=10, yticklabels=10)\n",
    "        \n",
    "        # Set custom x-axis ticks showing the prediction distance\n",
    "        tick_positions = np.linspace(0, 2 * max_distance, 9)\n",
    "        tick_labels = np.linspace(-max_distance, max_distance, 9).astype(int)\n",
    "        plt.xticks(tick_positions, tick_labels)\n",
    "        \n",
    "        # Add vertical lines at +/- 5 years\n",
    "        center_idx = max_distance\n",
    "        plt.axvline(x=center_idx + 5, color='r', linestyle='--', alpha=0.7)\n",
    "        plt.axvline(x=center_idx - 5, color='r', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Set y-axis ticks for true age\n",
    "        y_tick_positions = np.arange(0, max_target_age + 1, 10)\n",
    "        plt.yticks(y_tick_positions, y_tick_positions)\n",
    "        \n",
    "        plt.xlabel('Prediction Distance (Predicted - True)')\n",
    "        plt.ylabel('True Age')\n",
    "        plt.title('Age Prediction Distance Heatmap (Normalized)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'age_distance_heatmap.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 8. Plot a random subset of predictions - REDUCED SIZE\n",
    "        if num_samples > 0:\n",
    "            sample_indices = np.random.choice(len(all_preds), min(num_samples, len(all_preds)), replace=False)\n",
    "            visualize_classification_predictions(\n",
    "                [all_filenames[i] for i in sample_indices],\n",
    "                [targets[i] for i in sample_indices],\n",
    "                [predictions[i] for i in sample_indices],\n",
    "                test_loader.dataset.img_dir,\n",
    "                results_dir\n",
    "            )\n",
    "        \n",
    "        # 9. Plot absolute error vs. true age as a scatter plot with density - REDUCED SIZE\n",
    "        plt.figure(figsize=(8, 6))  # Reduced from (12, 8)\n",
    "        \n",
    "        # Create hexbin plot for density visualization\n",
    "        hb = plt.hexbin(targets, errors, gridsize=25, cmap='Blues', mincnt=1)\n",
    "        plt.colorbar(hb, label='Count')\n",
    "        \n",
    "        # Add a horizontal line at error = 5\n",
    "        plt.axhline(y=5, color='r', linestyle='--', alpha=0.7, label='5-year threshold')\n",
    "        \n",
    "        plt.xlabel('True Age')\n",
    "        plt.ylabel('Absolute Error (years)')\n",
    "        plt.title('Prediction Error vs True Age')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'error_vs_age_density.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 10. Plot the probability distribution for selected ages - REDUCED SIZE\n",
    "        # Choose a few interesting ages to visualize\n",
    "        ages_to_visualize = [5, 20, 40, 60, 80]\n",
    "        plt.figure(figsize=(8, 6))  # Reduced from (15, 10)\n",
    "        \n",
    "        for age in ages_to_visualize:\n",
    "            # Find examples with the true age\n",
    "            indices = np.where(targets == age)[0]\n",
    "            if len(indices) > 0:\n",
    "                # Average the probability distributions\n",
    "                avg_probs = np.mean(probabilities[indices], axis=0)\n",
    "                \n",
    "                # Plot probabilities for a range around the true age\n",
    "                window = 40\n",
    "                start_idx = max(0, age - window)\n",
    "                end_idx = min(len(avg_probs), age + window + 1)\n",
    "                x_range = np.arange(start_idx, end_idx)\n",
    "                \n",
    "                plt.plot(x_range, avg_probs[start_idx:end_idx], label=f'Age {age}')\n",
    "                plt.axvline(x=age, linestyle='--', alpha=0.5, color='gray')\n",
    "        \n",
    "        plt.xlabel('Age Class')\n",
    "        plt.ylabel('Average Probability')\n",
    "        plt.title('Average Probability Distribution for Selected Ages')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'probability_distributions.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # Save detailed results to CSV\n",
    "    results_df = pd.DataFrame({\n",
    "        'filename': all_filenames,\n",
    "        'true_age': targets,\n",
    "        'predicted_age': predictions,\n",
    "        'absolute_error': errors,\n",
    "        'within_5_years': errors <= 5  # Add a binary column for within 5 years\n",
    "    })\n",
    "    \n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    results_df.to_csv(os.path.join(results_dir, 'classification_results.csv'), index=False)\n",
    "    print(f\"Saved detailed results to {results_dir}/classification_results.csv\")\n",
    "    \n",
    "    # Generate a summary statistics file\n",
    "    with open(os.path.join(results_dir, 'summary_stats.txt'), 'w') as f:\n",
    "        f.write(\"SUMMARY STATISTICS\\n\")\n",
    "        f.write(\"=================\\n\\n\")\n",
    "        f.write(f\"Model Name: {model_path}\\n\")\n",
    "        f.write(\"=================\\n\\n\")\n",
    "        f.write(f\"Test dataset size: {len(test_loader.dataset)} images\\n\")\n",
    "        f.write(f\"Mean Absolute Error: {avg_mae:.2f} years\\n\")\n",
    "        f.write(f\"Accuracy (exact match): {accuracy:.2%}\\n\\n\")\n",
    "        \n",
    "        f.write(\"PREDICTIONS WITHIN ERROR THRESHOLDS\\n\")\n",
    "        f.write(\"==================================\\n\")\n",
    "        f.write(f\"Within 1 year: {within_1_year:.2f}%\\n\")\n",
    "        f.write(f\"Within 3 years: {within_3_years:.2f}%\\n\")\n",
    "        f.write(f\"Within 5 years: {within_5_years:.2f}%\\n\")\n",
    "        f.write(f\"Within 10 years: {within_10_years:.2f}%\\n\\n\")\n",
    "        \n",
    "        f.write(\"METRICS BY AGE GROUP\\n\")\n",
    "        f.write(\"===================\\n\")\n",
    "        for start, end, name in age_groups:\n",
    "            mask = (targets >= start) & (targets <= end)\n",
    "            if np.sum(mask) > 0:\n",
    "                group_accuracy = np.mean(targets[mask] == predictions[mask])\n",
    "                group_mae = np.mean(errors[mask])\n",
    "                group_within_5 = np.mean(errors[mask] <= 5) * 100\n",
    "                count = np.sum(mask)\n",
    "                f.write(f\"{name}:\\n\")\n",
    "                f.write(f\"  - Sample size: {count}\\n\")\n",
    "                f.write(f\"  - Accuracy: {group_accuracy:.2%}\\n\")\n",
    "                f.write(f\"  - MAE: {group_mae:.2f} years\\n\")\n",
    "                f.write(f\"  - Within 5 years: {group_within_5:.2f}%\\n\\n\")\n",
    "    \n",
    "    print(f\"Saved summary statistics to {results_dir}/summary_stats.txt\")\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'mae': avg_mae,\n",
    "        'within_5_years': within_5_years,\n",
    "        'predictions': predictions,\n",
    "        'targets': targets,\n",
    "        'filenames': all_filenames,\n",
    "        'errors': errors,\n",
    "        'probabilities': probabilities,\n",
    "        'results_dir': results_dir\n",
    "    }\n",
    "\n",
    "# Helper function to visualize classification predictions - REDUCED SIZE\n",
    "def visualize_classification_predictions(filenames, true_ages, pred_ages, img_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Visualize predictions for a few samples\n",
    "    \n",
    "    Args:\n",
    "        filenames: List of image filenames\n",
    "        true_ages: List of true ages\n",
    "        pred_ages: List of predicted ages\n",
    "        img_dir: Directory containing the images\n",
    "        output_dir: Directory to save the visualization\n",
    "    \"\"\"\n",
    "    n_samples = len(filenames)\n",
    "    n_cols = min(5, n_samples)\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    \n",
    "    # Limit the number of rows to 3 (15 samples max)\n",
    "    n_rows = min(n_rows, 3)\n",
    "    n_samples = min(n_samples, n_cols * n_rows)\n",
    "    \n",
    "    plt.figure(figsize=(n_cols * 2, n_rows * 2))  # Reduced from (n_cols * 3, n_rows * 4)\n",
    "    \n",
    "    for i, (filename, true_age, pred_age) in enumerate(zip(filenames[:n_samples], true_ages[:n_samples], pred_ages[:n_samples])):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        \n",
    "        # Load and display the image\n",
    "        img_path = os.path.join(img_dir, filename)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        # Add true and predicted ages as text\n",
    "        error = abs(true_age - pred_age)\n",
    "        within_5 = \"✓\" if error <= 5 else \"✗\"\n",
    "        color = 'green' if error <= 5 else 'red'\n",
    "        plt.title(f\"True: {true_age}\\nPred: {pred_age}\\n{within_5}\", color=color, fontsize=8)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'sample_predictions.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Main function for testing\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Set up for reproducibility\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "# Set up for reproducibility\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Define paths\n",
    "    test_csv = '/home/meem/backup/Age Datasets/UTKFace/crop_part1/test_annotations.csv'\n",
    "    test_dir = '/home/meem/backup/Age Datasets/UTKFace/crop_part1/test'\n",
    "    \n",
    "    # Use your trained model file\n",
    "    model_path = 'output/volo_d1_gradual_final.pth'  # Change to your model path\n",
    "\n",
    "    # model_path = 'Resnet-codes/output/resnet50_crossentropy_final.pth'  # Change to your model path\n",
    "    \n",
    "    \n",
    "    # Test transforms (same as validation)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create test dataset and dataloader\n",
    "    test_dataset = AgeClassificationDataset(\n",
    "        csv_file=test_csv,\n",
    "        img_dir=test_dir,\n",
    "        transform=test_transform\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=16, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Test dataset size: {len(test_dataset)} images\")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_model(model_path, device, num_classes=122)\n",
    "    \n",
    "    # Test model\n",
    "    results = test_classification_model(\n",
    "        model_path = model_path,\n",
    "        model=model, \n",
    "        test_loader=test_loader, \n",
    "        device=device,\n",
    "        visualize=True,\n",
    "        num_samples=15,\n",
    "        max_age=100  # Limit visualization to ages 0-100\n",
    "    )\n",
    "\n",
    "    # Call this function after your test_classification_model function\n",
    "    create_complete_age_prediction_scatter(results['predictions'], results['targets'], results['results_dir'])\n",
    "\n",
    "    \n",
    "    # Print key results\n",
    "    print(\"\\nKEY RESULTS SUMMARY:\")\n",
    "    print(f\"Mean Absolute Error: {results['mae']:.2f} years\")\n",
    "    print(f\"Percentage within 5 years: {results['within_5_years']:.2f}%\")\n",
    "    print(f\"All results saved in directory: {results['results_dir']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
